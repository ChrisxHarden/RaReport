# June 1 Report


## TODO:
1. jukebooks
2. rq-va
3. ImageBart
4. parti

## Done:
1. Changed into aaai format
2. Concluded the finished papers 
## Doing:
1.  Reading: Align your Latents-
High-Resolution Video Synthesis with Latent Diffusion Models
2. transform today's finished papers' conclusion onto overleaf




----------------------

## quetions to be asked:
1. I am trying to figure out whether my understanding of Dall-E and VQ-VAE or VQ-GAN is correct or not: Dall-E use a dVAE to transform the original image into a grid of values with each of them have 8192 possible values. The VQ-VAE use the VAE to first encode the input image and then replace it with the closest vector from the leart codebook. If that's correct, then can I assume the difference of them is the different latent space? Dall-e 's latent space is 2-D and VQ-VAE's latent space is comprised of vectors? 
2. Should I look at 3d generating?


   



------------------------
## Conclusion(quick notes) on papers

### Vector Quantized Diffusion Model for Text-to-Image Synthesis
1. Description: 
   obtain the discrete image tokens with pre-trained VQ-VAE
   text tokens obtained through BPE-encoding
   
   model the vq-vae's latent space in a non-autoregressive manner to address the problem of unidirectional bias and accumulation errorï¼Œ using a conditional variant of the Denoising Diffusion Probabilistic Model (DDPM) with Mask-and-replace diffusion strategy.
2. Similarity: Using Vector Quantization, adopt VQ-VAE as the way to form the latent codebook
3. Differentce: Didn't build the generative model in an autoregrssive way.

### High-Resolution Image Synthesis with Latent Diffusion Models

1. Description:
   Using the compression scheme same as VQ-GAN but with 2 different relgularizaions. T
   
   using kl-penalty , or put a vector quantization layer in the decoder.

   form the latent space as 2-D to exploit latent space's inhert structure, the compression rate can be low and good image quality can be absorbed

   The diffusion model use U-net as the backbone structure to better utilize the 2-D latent space, and a cross-attention layer is added to U-Net to perform conditional image generating with the instructions' various input modalities

### LION: Latent Point Diffusion Models for 3D Shape Generation
Using hirerachical point-cloud VAEs for latent space creation, one is shape latent, the other is points cloud latent space. Learnt 2 DMs on those 2 latent space as generative models

### Zero-Shot Text-to-Image Generation
train a discrete variational autoencoder (dVAE) to compress each image into a grid of image tokens for the image, each token can be one of 8192 values. What's different from VQ-VAE or VQ-GAN as it's comprised of values rather than vectors. Then BPE-encoded text tokens will be concanated for autoregressive transformers to model the joint distribution.





--------------------------
## Quick Notes
1. styleclip
2. latent point diffusion models for 3d shape generation
3. latent space diffusion models of cryo-em
4. symbolic music generation with diffusion models

