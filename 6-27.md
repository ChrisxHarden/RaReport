## Todo

## Done
1. Finish the collection of the datasets.
2. had a quick look at the paper:"Revisiting Pretraining Objectives for Tabular Deep Learning",but it didn't mention how it preprocess the data.
## Doing


## Questions
1. From the datasets I have collected, some of them are not traditional tasks like regression and classification. For example, this is clustering, this is predicting missing value from given table, and this is to blend existing files to improve prediction score. Should we tranform these datasets into autodataset as well?
2. should I make the tabular dataset also memory mapped? Since some datasets are huge, if we need to perform memory mapped, I am thinking about feature reduction or distillation.
3. I am going to follow the auto-ds repo's style and expand it to tabular datasets.
4. possible curation: outliner detection, filling in the missing value, 